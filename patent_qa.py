import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import json
from datetime import datetime

# ì••ì¶•í•´ì œ
import zipfile, os

if not os.path.exists("final_patent_chunking_results.json"):
    with zipfile.ZipFile("data.zip", "r") as z:
        z.extractall(".")


# OpenAI API ì„¤ì •
import os
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


class PatentQAChatbot:
    def __init__(self, json_file_path: str):
        """íŠ¹í—ˆ QA ì±—ë´‡ ì´ˆê¸°í™” (ë‹¤ì¤‘ ë¬¸ì„œ ì°¸ì¡°)"""
        print("ğŸ¤– íŠ¹í—ˆ QA ì±—ë´‡ì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        
        # JSON íŒŒì¼ ì½ê¸°
        self.patents_data = self._load_json(json_file_path)
        
        # ì¶œì›ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
        self.patent_ids = list(self.patents_data.keys())
        print(f"âœ“ ì´ {len(self.patent_ids)}ê°œ íŠ¹í—ˆ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        
        # ë²¡í„°í™”ìš© ìš”ì•½ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        self.summaries = []
        for patent_id in self.patent_ids:
            summary = self.patents_data[patent_id].get('patent_summary', '')
            self.summaries.append(summary)
        
        # TF-IDF ë²¡í„°í™”
        self.vectorizer = TfidfVectorizer(
            max_features=10000,
            ngram_range=(1, 2),
            min_df=1
        )
        self.summary_vectors = self.vectorizer.fit_transform(self.summaries)
        
        print("âœ… ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!\n")
    
    def _load_json(self, json_file_path: str) -> dict:
        """JSON íŒŒì¼ ë¡œë“œ"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ“ JSON íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            return data
        except FileNotFoundError:
            raise Exception(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file_path}")
        except json.JSONDecodeError:
            raise Exception(f"JSON íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: {json_file_path}")
    
    def _find_top_relevant_patents(self, question: str, top_k: int = 3) -> list:
        """
        ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ íŠ¹í—ˆ top_kê°œ ì°¾ê¸°
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ìƒìœ„ kê°œ íŠ¹í—ˆ (ìµœëŒ€ 3ê°œ)
        
        Returns:
            [(patent_id, similarity_score, index), ...] ë¦¬ìŠ¤íŠ¸
        """
        question_vector = self.vectorizer.transform([question])
        similarities = cosine_similarity(question_vector, self.summary_vectors).flatten()
        
        # ìœ ì‚¬ë„ê°€ 0ë³´ë‹¤ í° ê²ƒë§Œ í•„í„°ë§
        valid_indices = np.where(similarities > 0)[0]
        if len(valid_indices) == 0:
            return []
        
        # ìƒìœ„ top_kê°œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            if similarities[idx] > 0:  # ìœ ì‚¬ë„ 0 ì´ˆê³¼ë§Œ
                patent_id = self.patent_ids[idx]
                results.append((patent_id, similarities[idx], idx))
        
        return results
    
    def _get_content_chunks(self, patent_id: str) -> list:
        """íŠ¹í—ˆì˜ content_chunks ê°€ì ¸ì˜¤ê¸°"""
        patent_data = self.patents_data.get(patent_id, {})
        content_chunks = patent_data.get('content_chunks', [])
        
        # ê° ì²­í¬ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        chunk_texts = []
        for chunk in content_chunks:
            text = chunk.get('text', '')
            if text and text.strip():
                chunk_texts.append(text)
        
        return chunk_texts
    
    def _generate_answer_from_chunk(self, question: str, chunk: str) -> tuple:
        """ì²­í¬ì—ì„œ ë‹µë³€ ìƒì„±"""
        prompt = f"""ë‹¹ì‹ ì€ íŠ¹í—ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œì„ ì‚¬ìš©í•˜ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{chunk}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ì •í™•í•œ ì •ë³´ë§Œ ì œê³µí•˜ëŠ” íŠ¹í—ˆ ë¶„ì„ ì „ë¬¸ê°€"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=400,
                temperature=0.3
            )
            
            answer = response.choices[0].message.content.strip()
            
            # ìœ íš¨í•œ ë‹µë³€ì¸ì§€ í™•ì¸
            has_answer = not any(phrase in answer.lower() for phrase in [
                "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", "ì–¸ê¸‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
                "ë‚˜ì™€ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤", "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            ])
            
            return answer, has_answer
            
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {e}", False
    
    def _get_answers_from_patent(self, question: str, patent_id: str) -> list:
        """
        í•˜ë‚˜ì˜ íŠ¹í—ˆ ë¬¸ì„œì—ì„œ ëª¨ë“  ì²­í¬ë¥¼ ê²€í† í•˜ì—¬ ìœ íš¨í•œ ë‹µë³€ ìˆ˜ì§‘
        
        Returns:
            ìœ íš¨í•œ ë‹µë³€ ë¦¬ìŠ¤íŠ¸
        """
        chunks = self._get_content_chunks(patent_id)
        valid_answers = []
        
        for chunk in chunks:
            answer, has_answer = self._generate_answer_from_chunk(question, chunk)
            if has_answer:
                valid_answers.append(answer)
        
        return valid_answers
    
    def _synthesize_multi_patent_answers(self, question: str, patent_answers: dict) -> str:
        """
        ì—¬ëŸ¬ íŠ¹í—ˆ ë¬¸ì„œì˜ ë‹µë³€ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…í•©
        
        Args:
            question: ì§ˆë¬¸
            patent_answers: {patent_id: [ë‹µë³€1, ë‹µë³€2, ...], ...}
        
        Returns:
            ì¢…í•©ëœ ìµœì¢… ë‹µë³€
        """
        if not patent_answers:
            return "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ëª¨ë“  ë‹µë³€ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (íŠ¹í—ˆ êµ¬ë¶„ ì—†ì´)
        all_answers = []
        for patent_id, answers in patent_answers.items():
            all_answers.extend(answers)
        
        if not all_answers:
            return "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ëª¨ë“  ë‹µë³€ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ
        combined_content = "\n\n".join(all_answers)
        
        synthesis_prompt = f"""ë‹¹ì‹ ì€ íŠ¹í—ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ì—¬ëŸ¬ íŠ¹í—ˆ ë¬¸ì„œì—ì„œ ì¶”ì¶œí•œ ì •ë³´ë“¤ì…ë‹ˆë‹¤.
ì´ ì •ë³´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê³  ìœ ê¸°ì ì¸ í•˜ë‚˜ì˜ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¤‘ìš”: 
- "ì²« ë²ˆì§¸ íŠ¹í—ˆì—ì„œëŠ”...", "ë‹¤ë¥¸ íŠ¹í—ˆì—ì„œëŠ”..." ê°™ì€ êµ¬ë¶„ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë§ˆì¹˜ í•˜ë‚˜ì˜ ì™„ì „í•œ ë¬¸ì„œë¥¼ ì½ê³  ë‹µë³€í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”
- ì—¬ëŸ¬ ì¶œì²˜ì˜ ë‚´ìš©ì„ ë§¤ë„ëŸ½ê²Œ í†µí•©í•˜ì—¬ ì „ë¬¸ê°€ ë‹µë³€ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”
- ë°˜ë³µë˜ëŠ” ë‚´ìš©ì€ í•œ ë²ˆë§Œ ì–¸ê¸‰í•˜ê³ , ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆë‹¤ë©´ í†µí•©ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- ì¶œì²˜ë‚˜ ì¶œì›ë²ˆí˜¸ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”

ì§ˆë¬¸: {question}

ì°¸ê³  ì •ë³´:
{combined_content}

ë‹µë³€ (ìì—°ìŠ¤ëŸ½ê³  í†µí•©ëœ í•˜ë‚˜ì˜ ë‹µë³€):"""
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ì—¬ëŸ¬ ì¶œì²˜ì˜ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì—¬ í•˜ë‚˜ì˜ ì™„ê²°ëœ ì „ë¬¸ê°€ ë‹µë³€ì„ ì œê³µí•˜ëŠ” íŠ¹í—ˆ ë¶„ì„ ì „ë¬¸ê°€"},
                    {"role": "user", "content": synthesis_prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            synthesized_answer = response.choices[0].message.content.strip()
            
            # ê°ì£¼ ì œê±° - ë‹µë³€ë§Œ ë°˜í™˜
            return synthesized_answer
            
        except Exception as e:
            return f"ë‹µë³€ ì¢…í•© ì¤‘ ì˜¤ë¥˜: {e}"
    
    def ask(self, question: str, verbose: bool = True, max_patents: int = 3) -> dict:
        """
        ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° (ë‹¤ì¤‘ ë¬¸ì„œ ì°¸ì¡°)
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            verbose: ìƒì„¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
            max_patents: ì°¸ì¡°í•  ìµœëŒ€ íŠ¹í—ˆ ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’: 3)
        
        Returns:
            ë‹µë³€ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        """
        if verbose:
            print(f"\nğŸ’¬ ì§ˆë¬¸: {question}")
            print("=" * 60)
        
        # 1. ê´€ë ¨ íŠ¹í—ˆ top 3 ì°¾ê¸°
        top_patents = self._find_top_relevant_patents(question, top_k=max_patents)
        
        if not top_patents:
            result = {
                "question": question,
                "answer": "ê´€ë ¨ íŠ¹í—ˆ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "application_numbers": [],
                "similarity_scores": [],
                "timestamp": datetime.now().isoformat()
            }
            if verbose:
                print("âŒ ê´€ë ¨ íŠ¹í—ˆ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n")
            return result
        
        if verbose:
            print(f"ğŸ” ìƒìœ„ {len(top_patents)}ê°œ ê´€ë ¨ íŠ¹í—ˆ ë°œê²¬:")
            for i, (patent_id, sim, _) in enumerate(top_patents, 1):
                print(f"   {i}. ğŸ“‹ ì¶œì›ë²ˆí˜¸: {patent_id} (ìœ ì‚¬ë„: {sim:.3f})")
        
        # 2. ê° íŠ¹í—ˆì—ì„œ ë‹µë³€ ìˆ˜ì§‘
        patent_answers = {}
        total_chunks = 0
        total_valid = 0
        
        for patent_id, similarity, idx in top_patents:
            if verbose:
                print(f"\nğŸ“„ [{patent_id}] ë¶„ì„ ì¤‘...")
            
            answers = self._get_answers_from_patent(question, patent_id)
            chunks = self._get_content_chunks(patent_id)
            
            total_chunks += len(chunks)
            
            if answers:
                patent_answers[patent_id] = answers
                total_valid += len(answers)
                if verbose:
                    print(f"   âœ“ {len(chunks)}ê°œ ì²­í¬ ì¤‘ {len(answers)}ê°œì—ì„œ ë‹µë³€ ë°œê²¬")
            else:
                if verbose:
                    print(f"   - {len(chunks)}ê°œ ì²­í¬ ê²€í†  ì™„ë£Œ (ìœ íš¨ ë‹µë³€ ì—†ìŒ)")
        
        if verbose:
            print(f"\nğŸ“Š ì´ {total_chunks}ê°œ ì²­í¬ ê²€í† , {total_valid}ê°œ ìœ íš¨ ë‹µë³€ ë°œê²¬")
            print("ğŸ” ë‹µë³€ ì¢…í•© ì¤‘...")
        
        # 3. ìµœì¢… ë‹µë³€ ì¢…í•©
        final_answer = self._synthesize_multi_patent_answers(question, patent_answers)
        
        result = {
            "question": question,
            "answer": final_answer,
            "application_numbers": [p[0] for p in top_patents],
            "similarity_scores": [float(p[1]) for p in top_patents],
            "patents_with_answers": list(patent_answers.keys()),
            "total_chunks_reviewed": total_chunks,
            "total_valid_answers": total_valid,
            "timestamp": datetime.now().isoformat()
        }
        
        if verbose:
            print("\nğŸ“ ìµœì¢… ë‹µë³€:")
            print("-" * 60)
            print(final_answer)
            print("=" * 60 + "\n")
        
        return result
    
    def chat(self):
        """ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘"""
        print("="*60)
        print("ğŸ¤– íŠ¹í—ˆ QA ì±—ë´‡ (ëŒ€í™”í˜• ëª¨ë“œ - ë‹¤ì¤‘ ë¬¸ì„œ ì°¸ì¡°)")
        print("="*60)
        print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', 'ì¢…ë£Œ' ì…ë ¥")
        print("-"*60 + "\n")
        
        chat_history = []
        
        while True:
            try:
                question = input("ğŸ’¬ ì§ˆë¬¸: ").strip()
                
                if not question:
                    continue
                
                if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                    print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                    break
                
                # ë‹µë³€ ìƒì„± (ìµœëŒ€ 3ê°œ íŠ¹í—ˆ ì°¸ì¡°)
                result = self.ask(question, verbose=True, max_patents=3)
                
                # íˆìŠ¤í† ë¦¬ ì €ì¥
                chat_history.append(result)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
        if chat_history:
            self.save_chat_history(chat_history)
    
    def save_chat_history(self, history: list, filename: str = "chat_history.json"):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ëŒ€í™” ë‚´ì—­ì´ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"\nâŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def batch_process(self, questions: list, output_file: str = "batch_results.json", max_patents: int = 3):
        """ì—¬ëŸ¬ ì§ˆë¬¸ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬ (ë‹¤ì¤‘ ë¬¸ì„œ ì°¸ì¡°)"""
        print(f"\nğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(questions)}ê°œ ì§ˆë¬¸ (ìµœëŒ€ {max_patents}ê°œ íŠ¹í—ˆ ì°¸ì¡°)")
        print("="*60)
        
        results = []
        for i, question in enumerate(questions, 1):
            print(f"\n[{i}/{len(questions)}] ì²˜ë¦¬ ì¤‘: {question[:50]}...")
            result = self.ask(question, verbose=False, max_patents=max_patents)
            results.append(result)
            print(f"âœ“ ì™„ë£Œ - {len(result['patents_with_answers'])}ê°œ íŠ¹í—ˆì—ì„œ ë‹µë³€ ìƒì„±")
        
        # ê²°ê³¼ ì €ì¥
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nâœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"\nâŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return results
